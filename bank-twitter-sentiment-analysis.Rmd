---
title: "Sentiment Analysis of Tweets to Banks"
output: html_notebook
---

```{r setup}

library(tidyverse)
library(stringr)
library(twitteR)
library(tidytext)

source("credentials")

#Authenticate with Twitter
setup_twitter_oauth(consumer_key = consumer_key,
                    consumer_secret = consumer_secret,
                    access_token = access_token,
                    access_secret = access_token_secret)
```



# Creating our function

## What do I want to do?

For each *bank* passed to the function, I want to:

* Gather tweets to it (how many)?
* Perform sentiment analysis on the gathered tweets
* Create a calculation of proportion

```{r}

analyse_tweets <- function(bank) {
  search_string <- paste("to:", bank, "+?", sep = "")
  tweets <- searchTwitter(search_string, n = 200)

# Convert to DF
  tidy_tweets <- tweets %>%
    twListToDF() %>% 
    select(created, id, text) %>%
    mutate(date = as.Date(created), bank = bank) %>%
    unnest_tokens(word, text) %>%
    anti_join(stop_words, by = c("word"))
  
  nrc_tidy_tweets <- tidy_tweets %>%
  inner_join(get_sentiments(lexicon = "nrc"), by = c("word"))
  
  
  nrc_tidy_tweets
}



get_tweets <- function(bank) {
  search_string <- paste("to:", bank, "+?", sep = "")
  tweets <- searchTwitter(search_string, n = 200) %>%
    twListToDF() %>% 
    select(created, id, text) %>%
    mutate(date = as.Date(created), bank = bank)
}

```

# What banks do we want to analyse?

I'd like to compare the big 4 banks in the UK, along with some of the smaller more "customer friendly" banks.
The larger banks often have multiple twitter handles for seperate (sometimes overlapping concerns). This muddies the waters our analysis a little, as people may tweet to different handles for different problems. 

For example, HSBC has @HSBC, @HSBC_UK and @HSBCUKBusiness. Barclays have @Barclays, @BarclaysUK, @BarclaysUKHelp, @barclaysuknews, @BarclaysAccess and @BarclaysBizChat.

Where they exist, I've taken the *customer service* twitter handle.

```{r}
banks <- c(HSBC = "HSBC_UK",
           Barclays = "BarclaysUKHelp", 
           Lloyds = "AskLloydsBank", 
           RBS = "RBS_Help", 
           First_Direct = "firstdirecthelp", 
           Monzo = "monzo", 
           Starling = "StarlingBank")


tweets <- map_dfr(banks, get_tweets)

# Use stop words from tidytext package
# Add banks twitter handles to stop words list
custom_stop_words <- bind_rows(data_frame(word = tolower(banks), 
                                          lexicon = c("custom")), 
                               stop_words)

words <- tweets %>%
  unnest_tokens(word, text) %>%
  anti_join(custom_stop_words, by = c("word"))

```


# Analysis


### What are the most popular words?
```{r}

words %>%
  count(word) %>%
  arrange(desc(n)) %>%
  top_n(25) %>%
  ggplot(aes(x = reorder(word, n), y = n)) + 
  geom_bar(stat = "identity") + 
  coord_flip() + 
  labs(x = "Word", y = "Count", title = "Most popular words in tweets")

```


### Sentiment Analysis


Need to be careful here.

Some banks have more tweets than others, so proportion of each sentiment must be normalised to compare between banks
```{r sentiment_analysis}
sentiment_proportions <- words %>%
  inner_join(get_sentiments("nrc"), by = "word") %>%
  group_by(bank) %>%
  mutate(total_n = n()) %>%
  group_by(bank, sentiment) %>%
  mutate(n = n(), sentiment_prop = (n/total_n) * 100 )


sentiment_proportions %>%
  ggplot(aes(x = sentiment, y = sentiment_prop)) +
  geom_bar(stat = "identity") +
  coord_flip() +
  facet_wrap(~bank)
```